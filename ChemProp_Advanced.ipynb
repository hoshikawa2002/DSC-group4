{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChemPropç²¾åº¦å‘ä¸Š - é«˜åº¦ãªæ‰‹æ³•ã«ã‚ˆã‚‹åˆ†å­ç‰¹æ€§äºˆæ¸¬\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ChemPropã®ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®é«˜åº¦ãªæ‰‹æ³•ã‚’å®Ÿè£…ã—ã¾ã™ï¼š\n",
    "1. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–\n",
    "2. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’\n",
    "3. RDKitå…¨è¨˜è¿°å­ï¼ˆ200å€‹ï¼‰ã®æ´»ç”¨\n",
    "4. ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–\n",
    "5. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ\n",
    "\n",
    "ç›®æ¨™: RÂ²ã‚¹ã‚³ã‚¢ 0.34 â†’ 0.6-0.8ã¸ã®å‘ä¸Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install chemprop rdkit optuna hyperopt scikit-learn pandas numpy matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ChemPropã¨RDKitã®èª­ã¿è¾¼ã¿\n",
    "try:\n",
    "    import chemprop\n",
    "    print(f\"ChemProp version: {chemprop.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"ChemPropã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors, rdMolDescriptors, Fragments\n",
    "    from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "    print(\"RDKitèª­ã¿è¾¼ã¿æˆåŠŸ\")\n",
    "except ImportError:\n",
    "    print(\"RDKitèª­ã¿è¾¼ã¿å¤±æ•—\")\n",
    "\n",
    "print(\"ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿\n",
    "df = pd.read_csv('starderdized_compounds_20240725.tsv', sep='\\t')\n",
    "\n",
    "print(f\"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å½¢çŠ¶: {df.shape}\")\n",
    "print(f\"ã‚«ãƒ©ãƒ å: {df.columns.tolist()}\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "df_clean = df.copy()\n",
    "for col in df_clean.columns:\n",
    "    df_clean[col] = df_clean[col].apply(lambda x: str(x).rstrip())\n",
    "    df_clean[col] = df_clean[col].replace('', None)\n",
    "\n",
    "# Inhibitionå€¤ã‚’æ•°å€¤ã«å¤‰æ›\n",
    "df_clean['Inhibition'] = pd.to_numeric(df_clean['Inhibition'], errors='coerce')\n",
    "\n",
    "# ChemPropç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n",
    "chemprop_data = df_clean[['washed_SMILES', 'Inhibition']].copy()\n",
    "chemprop_data.columns = ['smiles', 'inhibition']\n",
    "chemprop_data = chemprop_data.dropna()\n",
    "\n",
    "print(f\"ã‚¯ãƒªãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿: {len(chemprop_data)}è¡Œ\")\n",
    "print(f\"é˜»å®³å€¤ã®çµ±è¨ˆ: å¹³å‡={chemprop_data['inhibition'].mean():.4f}, æ¨™æº–åå·®={chemprop_data['inhibition'].std():.4f}\")\n",
    "\n",
    "# è¨“ç·´ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ï¼ˆ60:20:20ï¼‰\n",
    "train_data, temp_data = train_test_split(chemprop_data, test_size=0.4, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"\\nè¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_data)}å€‹\")\n",
    "print(f\"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(val_data)}å€‹\")\n",
    "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_data)}å€‹\")\n",
    "\n",
    "# CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "train_data.to_csv('train_advanced.csv', index=False)\n",
    "val_data.to_csv('val_advanced.csv', index=False)\n",
    "test_data.to_csv('test_advanced.csv', index=False)\n",
    "\n",
    "print(\"\\nãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RDKitå…¨è¨˜è¿°å­ï¼ˆ200å€‹ï¼‰ã®è¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_rdkit_descriptors(smiles_list):\n",
    "    \"\"\"\n",
    "    RDKitã®å…¨è¨˜è¿°å­ï¼ˆ200å€‹ï¼‰ã‚’è¨ˆç®—\n",
    "    \"\"\"\n",
    "    # åˆ©ç”¨å¯èƒ½ãªå…¨è¨˜è¿°å­åã‚’å–å¾—\n",
    "    descriptor_names = [desc[0] for desc in Descriptors._descList]\n",
    "    calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
    "    \n",
    "    descriptors = []\n",
    "    invalid_smiles_count = 0\n",
    "    \n",
    "    for smiles in smiles_list:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is not None:\n",
    "                desc = calculator.CalcDescriptors(mol)\n",
    "                # NaNã‚„ç„¡é™å¤§ã‚’0ã«ç½®æ›\n",
    "                desc = [0 if (np.isnan(d) or np.isinf(d)) else d for d in desc]\n",
    "                descriptors.append(desc)\n",
    "            else:\n",
    "                descriptors.append([0] * len(descriptor_names))\n",
    "                invalid_smiles_count += 1\n",
    "        except:\n",
    "            descriptors.append([0] * len(descriptor_names))\n",
    "            invalid_smiles_count += 1\n",
    "    \n",
    "    print(f\"ç„¡åŠ¹ãªSMILESæ•°: {invalid_smiles_count}\")\n",
    "    print(f\"è¨ˆç®—ã•ã‚ŒãŸè¨˜è¿°å­æ•°: {len(descriptor_names)}\")\n",
    "    \n",
    "    return np.array(descriptors), descriptor_names\n",
    "\n",
    "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®è¨˜è¿°å­ã‚’è¨ˆç®—\n",
    "print(\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®è¨˜è¿°å­è¨ˆç®—ä¸­...\")\n",
    "X_train_desc, descriptor_names = calculate_all_rdkit_descriptors(train_data['smiles'].tolist())\n",
    "\n",
    "print(\"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®è¨˜è¿°å­è¨ˆç®—ä¸­...\")\n",
    "X_val_desc, _ = calculate_all_rdkit_descriptors(val_data['smiles'].tolist())\n",
    "\n",
    "print(\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¨˜è¿°å­è¨ˆç®—ä¸­...\")\n",
    "X_test_desc, _ = calculate_all_rdkit_descriptors(test_data['smiles'].tolist())\n",
    "\n",
    "# è¨˜è¿°å­ã®æ­£è¦åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_train_desc_scaled = scaler.fit_transform(X_train_desc)\n",
    "X_val_desc_scaled = scaler.transform(X_val_desc)\n",
    "X_test_desc_scaled = scaler.transform(X_test_desc)\n",
    "\n",
    "print(f\"\\nè¨˜è¿°å­è¡Œåˆ—ã®å½¢çŠ¶:\")\n",
    "print(f\"è¨“ç·´: {X_train_desc_scaled.shape}\")\n",
    "print(f\"æ¤œè¨¼: {X_val_desc_scaled.shape}\")\n",
    "print(f\"ãƒ†ã‚¹ãƒˆ: {X_test_desc_scaled.shape}\")\n",
    "\n",
    "# è¨˜è¿°å­ã‚’CSVã¨ã—ã¦ä¿å­˜ï¼ˆChemPropã®è¿½åŠ ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ï¼‰\n",
    "train_desc_df = pd.DataFrame(X_train_desc_scaled, columns=descriptor_names)\n",
    "train_desc_df.to_csv('train_features.csv', index=False)\n",
    "\n",
    "val_desc_df = pd.DataFrame(X_val_desc_scaled, columns=descriptor_names)\n",
    "val_desc_df.to_csv('val_features.csv', index=False)\n",
    "\n",
    "test_desc_df = pd.DataFrame(X_test_desc_scaled, columns=descriptor_names)\n",
    "test_desc_df.to_csv('test_features.csv', index=False)\n",
    "\n",
    "print(\"è¨˜è¿°å­ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ï¼‰\n",
    "print(\"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’é–‹å§‹...\")\n",
    "print(\"ã“ã‚Œã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆ10-30åˆ†ç¨‹åº¦ï¼‰\")\n",
    "\n",
    "# ChemPropãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã®å®Ÿè¡Œï¼ˆå…ƒã®è¨­å®šã®ã¾ã¾ï¼‰\n",
    "hyperopt_command = [\n",
    "    'chemprop_hyperopt',\n",
    "    '--data_path', 'train_advanced.csv',\n",
    "    '--separate_val_path', 'val_advanced.csv',\n",
    "    '--dataset_type', 'regression',\n",
    "    '--save_dir', 'hyperopt_results',\n",
    "    '--config_save_path', 'hyperopt_results/best_config.json',\n",
    "    '--features_path', 'train_features.csv',\n",
    "    '--separate_val_features_path', 'val_features.csv',\n",
    "    '--num_iters', '15',   # å…ƒã®è¨­å®š\n",
    "    '--epochs', '80',      # å…ƒã®è¨­å®š\n",
    "    '--search_parameter_keywords',\n",
    "    'batch_size', 'depth', 'dropout', 'ffn_hidden_size', 'hidden_size', 'learning_rate',\n",
    "    '--seed', '42'\n",
    "]\n",
    "\n",
    "try:\n",
    "    os.makedirs('hyperopt_results', exist_ok=True)\n",
    "    print(\"å®Ÿè¡Œä¸­... ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—\")\n",
    "    \n",
    "    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ã§å®Ÿè¡Œ\n",
    "    result = subprocess.run(hyperopt_command, capture_output=True, text=True)\n",
    "    \n",
    "    print(f\"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–å®Œäº†! ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode}\")\n",
    "    \n",
    "    if result.stdout:\n",
    "        print(\"æ¨™æº–å‡ºåŠ› (æœ€å¾Œã®1000æ–‡å­—):\")\n",
    "        print(result.stdout[-1000:])\n",
    "    if result.stderr:\n",
    "        print(\"ã‚¨ãƒ©ãƒ¼å‡ºåŠ› (æœ€å¾Œã®500æ–‡å­—):\")\n",
    "        print(result.stderr[-500:])\n",
    "        \n",
    "    # æœ€é©åŒ–çµæœã®èª­ã¿è¾¼ã¿ï¼ˆè¤‡æ•°ã®å ´æ‰€ã‚’è©¦è¡Œï¼‰\n",
    "    config_files = [\n",
    "        'hyperopt_results/best_config.json',\n",
    "        'hyperopt_results/hyperopt_results.json',\n",
    "        'hyperopt_results/config_0.json'\n",
    "    ]\n",
    "    \n",
    "    best_params_loaded = False\n",
    "    for config_file in config_files:\n",
    "        try:\n",
    "            if os.path.exists(config_file):\n",
    "                print(f\"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {config_file}\")\n",
    "                with open(config_file, 'r') as f:\n",
    "                    config_data = json.load(f)\n",
    "                \n",
    "                # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«å¿œã˜ã¦å‡¦ç†\n",
    "                if isinstance(config_data, list) and len(config_data) > 0:\n",
    "                    best_params = config_data[0]\n",
    "                elif isinstance(config_data, dict):\n",
    "                    best_params = config_data\n",
    "                else:\n",
    "                    print(f\"âš ï¸  {config_file}: äºˆæœŸã—ãªã„ãƒ‡ãƒ¼ã‚¿å½¢å¼\")\n",
    "                    continue\n",
    "                    \n",
    "                print(f\"\\nğŸ¯ æœ€é©ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ({config_file}):\")\n",
    "                for key, value in best_params.items():\n",
    "                    if key not in ['mean_score', 'std_score']:\n",
    "                        print(f\"   {key}: {value}\")\n",
    "                if 'mean_score' in best_params:\n",
    "                    print(f\"   ğŸ“Š æœ€è‰¯ã‚¹ã‚³ã‚¢: {best_params.get('mean_score', 'N/A')}\")\n",
    "                \n",
    "                best_params_loaded = True\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {config_file}ã®èª­ã¿è¾¼ã¿å¤±æ•—: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not best_params_loaded:\n",
    "        print(\"âš ï¸  æœ€é©åŒ–çµæœã®èª­ã¿è¾¼ã¿ã«å¤±æ•—\")\n",
    "        print(\"ğŸ“ åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "        import glob\n",
    "        for f in glob.glob(\"hyperopt_results/*\"):\n",
    "            print(f\"     {f}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã§ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šï¼ˆæœ€é©åŒ–ãŒå¤±æ•—ã—ãŸå ´åˆï¼‰\n",
    "if 'best_params' not in locals() or not best_params:\n",
    "    print(\"\\nğŸ”„ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ”¹è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç¶šè¡Œ\")\n",
    "    best_params = {\n",
    "        'batch_size': 32,\n",
    "        'depth': 4,\n",
    "        'dropout': 0.1,\n",
    "        'ffn_hidden_size': 1000,\n",
    "        'ffn_num_layers': 3,\n",
    "        'hidden_size': 600,\n",
    "        'learning_rate': 0.0001\n",
    "    }\n",
    "    print(\"ğŸ“‹ ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "\n",
    "print(f\"\\nâœ… ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå®Œäº†\")\n",
    "print(f\"ğŸ“Š ä½¿ç”¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {len(best_params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” æœ€é©åŒ–çµæœã‚’æ­£ç¢ºè§£æä¸­...\")\n",
    "\n",
    "try:\n",
    "      with open('hyperopt_results/verbose.log', 'r') as f:\n",
    "          content = f.read()\n",
    "\n",
    "      lines = content.split('\\n')\n",
    "\n",
    "      # å„è©¦è¡Œã®çµæœã‚’åé›†\n",
    "      trials = []\n",
    "\n",
    "      i = 0\n",
    "      while i < len(lines):\n",
    "          line = lines[i].strip()\n",
    "\n",
    "          # \"Trial results with seed X\" ã®è¡Œã‚’ç™ºè¦‹\n",
    "          if line.startswith('Trial results with seed'):\n",
    "              # ã‚·ãƒ¼ãƒ‰ç•ªå·ã‚’æŠ½å‡º\n",
    "              import re\n",
    "              seed_match = re.search(r'seed (\\d+)', line)\n",
    "              if seed_match:\n",
    "                  seed = int(seed_match.group(1))\n",
    "\n",
    "                  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡Œï¼ˆæ¬¡ã®è¡Œï¼‰\n",
    "                  if i+1 < len(lines):\n",
    "                      param_line = lines[i+1].strip()\n",
    "\n",
    "                      # RMSEè¡Œã‚’æ¢ã™ï¼ˆãã®å¾Œã®æ•°è¡Œå†…ï¼‰\n",
    "                      rmse = None\n",
    "                      for j in range(2, 6):  # 2-5è¡Œå¾Œã‚’ãƒã‚§ãƒƒã‚¯\n",
    "                          if i+j < len(lines):\n",
    "                              rmse_line = lines[i+j].strip()\n",
    "                              if '+/- 0.0 rmse' in rmse_line:\n",
    "                                  # RMSEå€¤ã‚’æŠ½å‡º\n",
    "                                  rmse_match = re.match(r'^([0-9.]+) \\+/- 0\\.0 rmse$', rmse_line)\n",
    "                                  if rmse_match:\n",
    "                                      rmse = float(rmse_match.group(1))\n",
    "                                      break\n",
    "\n",
    "                      # æœ‰åŠ¹ãªçµæœã®å ´åˆ\n",
    "                      if rmse is not None:\n",
    "                          try:\n",
    "                              # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ã‚’å®‰å…¨ã«è©•ä¾¡\n",
    "                              if param_line.startswith('{') and param_line.endswith('}'):\n",
    "                                  params_dict = eval(param_line)\n",
    "                                  trials.append((seed, rmse, params_dict))\n",
    "                                  print(f\"ğŸ“Š seed {seed}: RMSE {rmse:.5f}\")\n",
    "                          except Exception as e:\n",
    "                              print(f\"âš ï¸  seed {seed}: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æå¤±æ•— - {e}\")\n",
    "          i += 1\n",
    "\n",
    "      if trials:\n",
    "          # RMSEæœ€å°ã®è©¦è¡Œã‚’é¸æŠ\n",
    "          best_trial = min(trials, key=lambda x: x[1])\n",
    "          best_seed, best_rmse, best_params_raw = best_trial\n",
    "\n",
    "          # ChemPropã§ä½¿ç”¨ã™ã‚‹å½¢å¼ã«å¤‰æ›\n",
    "          best_params = {\n",
    "              'batch_size': best_params_raw.get('batch_size', 32),\n",
    "              'depth': best_params_raw.get('depth', 4),\n",
    "              'dropout': best_params_raw.get('dropout', 0.1),\n",
    "              'ffn_hidden_size': best_params_raw.get('ffn_hidden_size', 1000),\n",
    "              'ffn_num_layers': best_params_raw.get('ffn_num_layers', 3),\n",
    "              'hidden_size': best_params_raw.get('hidden_size', 600),\n",
    "              'learning_rate': best_params_raw.get('max_lr', 0.0001)\n",
    "          }\n",
    "\n",
    "          print(f\"\\nğŸ† æœ€è‰¯çµæœç™ºè¦‹: seed {best_seed}\")\n",
    "          print(f\"ğŸ¯ æœ€è‰¯RMSE: {best_rmse:.6f}\")\n",
    "          print(f\"ğŸ“ˆ å…ƒã®ChemProp(0.1990)ã¨ã®æ¯”è¼ƒ: {((best_rmse/0.1990 - 1)*100):+.1f}%\")\n",
    "          print(f\"ğŸ“Š è§£æã•ã‚ŒãŸè©¦è¡Œæ•°: {len(trials)}\")\n",
    "\n",
    "          print(\"\\nâœ… ç™ºè¦‹ã•ã‚ŒãŸæœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
    "          for k, v in best_params.items():\n",
    "              print(f\"   {k}: {v}\")\n",
    "\n",
    "          # è©¦è¡Œçµ±è¨ˆ\n",
    "          all_rmse = [trial[1] for trial in trials]\n",
    "          print(f\"\\nğŸ“ˆ å…¨è©¦è¡Œçµ±è¨ˆ:\")\n",
    "          print(f\"   æœ€è‰¯RMSE: {min(all_rmse):.6f}\")\n",
    "          print(f\"   æœ€æ‚ªRMSE: {max(all_rmse):.6f}\")\n",
    "          print(f\"   å¹³å‡RMSE: {sum(all_rmse)/len(all_rmse):.6f}\")\n",
    "\n",
    "      else:\n",
    "          raise ValueError(\"æœ‰åŠ¹ãªè©¦è¡ŒçµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "\n",
    "except Exception as e:\n",
    "      print(f\"âŒ è§£æå¤±æ•—: {e}\")\n",
    "      print(\"ğŸš¨ ãƒ­ã‚°å½¢å¼ç¢ºèªãŒå¿…è¦ã§ã™\")\n",
    "\n",
    "print(f\"\\nâœ… æº–å‚™å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®è¨“ç·´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§è¨“ç·´ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰\n",
    "      # æœ€é©åŒ–çµæœãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ä½¿ç”¨ã€ãªã‘ã‚Œã°ã‚¨ãƒ©ãƒ¼\n",
    "if 'best_params' in locals() and best_params:\n",
    "    print(\"ğŸ¯ 8æ™‚é–“ã®æœ€é©åŒ–çµæœã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹\")\n",
    "    print(\"âœ… ä½¿ç”¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "else:\n",
    "    print(\"âŒ ã‚¨ãƒ©ãƒ¼: best_paramsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    print(\"ğŸ’¡ ã‚»ãƒ«8.5ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "    raise ValueError(\"ã‚»ãƒ«8.5ã§best_paramsã‚’è¨­å®šã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "\n",
    "# æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´\n",
    "os.makedirs('optimized_model', exist_ok=True)\n",
    "\n",
    "train_command = [\n",
    "    'chemprop_train',\n",
    "    '--data_path', 'train_advanced.csv',\n",
    "    '--separate_val_path', 'val_advanced.csv',\n",
    "    '--dataset_type', 'regression',\n",
    "    '--save_dir', 'optimized_model',\n",
    "    '--features_path', 'train_features.csv',\n",
    "    '--separate_val_features_path', 'val_features.csv',\n",
    "    '--epochs', '100',\n",
    "    '--batch_size', str(best_params.get('batch_size', 32)),\n",
    "    '--depth', str(best_params.get('depth', 4)),\n",
    "    '--dropout', str(best_params.get('dropout', 0.1)),\n",
    "    '--ffn_hidden_size', str(best_params.get('ffn_hidden_size', 1000)),  # ä¿®æ­£æ¸ˆã¿\n",
    "    '--ffn_num_layers', str(best_params.get('ffn_num_layers', 3)),\n",
    "    '--hidden_size', str(best_params.get('hidden_size', 600)),\n",
    "    '--init_lr', str(best_params.get('learning_rate', 0.0001)),\n",
    "    '--seed', '42'\n",
    "]\n",
    "\n",
    "print(\"æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´é–‹å§‹...\")\n",
    "print(f\"ã‚³ãƒãƒ³ãƒ‰: {' '.join(train_command)}\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(train_command, capture_output=True, text=True)  # 20åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ\n",
    "    print(f\"è¨“ç·´å®Œäº†! ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode}\")\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æˆåŠŸ!\")\n",
    "    else:\n",
    "        print(\"è¨“ç·´ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ\")\n",
    "        \n",
    "    if result.stdout:\n",
    "        print(\"æ¨™æº–å‡ºåŠ›:\")\n",
    "        print(result.stdout[-500:])  # æœ€å¾Œã®500æ–‡å­—\n",
    "    if result.stderr:\n",
    "        print(\"ã‚¨ãƒ©ãƒ¼å‡ºåŠ›:\")\n",
    "        print(result.stderr[-500:])  # æœ€å¾Œã®500æ–‡å­—\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"è¨“ç·´ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ\")\n",
    "except Exception as e:\n",
    "    print(f\"è¨“ç·´ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "\n",
    "print(\"æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚»ã‚¯ã‚·ãƒ§ãƒ³å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã®å®Ÿè£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆ5ã¤ã®ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# best_paramsãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤\n",
    "if 'best_params' not in locals():\n",
    "    best_params = {\n",
    "        'batch_size': 32,\n",
    "        'depth': 4,\n",
    "        'dropout': 0.1,\n",
    "        'ffn_hidden_size': 1000,\n",
    "        'ffn_num_layers': 3,\n",
    "        'hidden_size': 600,\n",
    "        'learning_rate': 0.0001\n",
    "    }\n",
    "    print(\"âš ï¸  best_paramsãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨\")\n",
    "\n",
    "ensemble_size = 5\n",
    "ensemble_models = []\n",
    "\n",
    "print(f\"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’é–‹å§‹ï¼ˆ{ensemble_size}å€‹ã®ãƒ¢ãƒ‡ãƒ«ï¼‰...\")\n",
    "print(\"å„ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆ20-30åˆ†ç¨‹åº¦ï¼‰\")\n",
    "print(f\"ä½¿ç”¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    model_dir = f'ensemble_model_{i}'\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # å„ãƒ¢ãƒ‡ãƒ«ã§ç•°ãªã‚‹ã‚·ãƒ¼ãƒ‰ã‚’ä½¿ç”¨\n",
    "    seed = 42 + i\n",
    "    \n",
    "    ensemble_command = [\n",
    "        'chemprop_train',\n",
    "        '--data_path', 'train_advanced.csv',\n",
    "        '--separate_val_path', 'val_advanced.csv',\n",
    "        '--dataset_type', 'regression',\n",
    "        '--save_dir', model_dir,\n",
    "        '--features_path', 'train_features.csv',\n",
    "        '--separate_val_features_path', 'val_features.csv',\n",
    "        '--epochs', '80',\n",
    "        '--batch_size', str(best_params.get('batch_size', 32)),\n",
    "        '--depth', str(best_params.get('depth', 4)),\n",
    "        '--dropout', str(best_params.get('dropout', 0.1)),\n",
    "        '--ffn_hidden_size', str(best_params.get('ffn_hidden_size', 1000)),\n",
    "        '--ffn_num_layers', str(best_params.get('ffn_num_layers', 3)),\n",
    "        '--hidden_size', str(best_params.get('hidden_size', 600)),\n",
    "        '--init_lr', str(best_params.get('learning_rate', 0.0001)),\n",
    "        '--seed', str(seed)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ãƒ¢ãƒ‡ãƒ« {i+1}/{ensemble_size} è¨“ç·´é–‹å§‹... (seed={seed})\")\n",
    "    \n",
    "    try:\n",
    "        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ã§å®Ÿè¡Œ\n",
    "        result = subprocess.run(ensemble_command, capture_output=True, text=True)\n",
    "        \n",
    "        print(f\"ãƒ¢ãƒ‡ãƒ« {i+1} å®Œäº† - ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode}\")\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            ensemble_models.append(model_dir)\n",
    "            print(f\"âœ… ãƒ¢ãƒ‡ãƒ« {i+1} è¨“ç·´æˆåŠŸ\")\n",
    "        elif result.returncode == -9:\n",
    "            print(f\"âš ï¸  ãƒ¢ãƒ‡ãƒ« {i+1} ãƒ¡ãƒ¢ãƒªä¸è¶³ã§å¼·åˆ¶çµ‚äº† - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...\")\n",
    "            # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "            if os.path.exists(f\"{model_dir}/model.pt\") or os.path.exists(f\"{model_dir}/fold_0\"):\n",
    "                ensemble_models.append(model_dir)\n",
    "                print(f\"âœ… ãƒ¢ãƒ‡ãƒ« {i+1} éƒ¨åˆ†çš„ã«æˆåŠŸï¼ˆä½¿ç”¨å¯èƒ½ï¼‰\")\n",
    "            else:\n",
    "                print(f\"âŒ ãƒ¢ãƒ‡ãƒ« {i+1} ä½¿ç”¨ä¸å¯\")\n",
    "        else:\n",
    "            print(f\"âŒ ãƒ¢ãƒ‡ãƒ« {i+1} è¨“ç·´å¤±æ•— (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode})\")\n",
    "            if result.stderr and len(result.stderr) > 100:\n",
    "                print(f\"ã‚¨ãƒ©ãƒ¼è©³ç´°: {result.stderr[-200:]}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ¢ãƒ‡ãƒ« {i+1} å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’å®Œäº†\")\n",
    "print(f\"âœ… æˆåŠŸã—ãŸãƒ¢ãƒ‡ãƒ«æ•°: {len(ensemble_models)}/{ensemble_size}\")\n",
    "print(f\"ğŸ“ æˆåŠŸã—ãŸãƒ¢ãƒ‡ãƒ«: {ensemble_models}\")\n",
    "\n",
    "# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãŒå°‘ãªãã¨ã‚‚1ã¤æˆåŠŸã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª\n",
    "if len(ensemble_models) == 0:\n",
    "    print(\"âš ï¸  è­¦å‘Š: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ãŒ1ã¤ã‚‚æˆåŠŸã—ã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "    print(\"   å˜ä¸€ã®æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ã§ã®äºˆæ¸¬ã«é€²ã¿ã¾ã™\")\n",
    "elif len(ensemble_models) < 3:\n",
    "    print(f\"âš ï¸  è­¦å‘Š: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ãŒ{len(ensemble_models)}å€‹ã—ã‹æˆåŠŸã—ã¾ã›ã‚“ã§ã—ãŸï¼ˆæ¨å¥¨: 3å€‹ä»¥ä¸Šï¼‰\")\n",
    "    print(\"   åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’ç¶šè¡Œã—ã¾ã™\")\n",
    "else:\n",
    "    print(f\"ğŸ‰ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’æˆåŠŸ: {len(ensemble_models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™\")\n",
    "\n",
    "print(f\"\\næ¬¡ã¯ã‚»ãƒ«7ï¼ˆäºˆæ¸¬ã¨è©•ä¾¡ï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. äºˆæ¸¬ã¨è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. æœ€é©åŒ–å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ã®äºˆæ¸¬\n",
    "def predict_with_model(model_dir, test_file, features_file, output_file):\n",
    "    \"\"\"å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ\"\"\"\n",
    "    predict_command = [\n",
    "        'chemprop_predict',\n",
    "        '--test_path', test_file,\n",
    "        '--checkpoint_dir', model_dir,\n",
    "        '--features_path', features_file,\n",
    "        '--preds_path', output_file\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(predict_command, capture_output=True, text=True, timeout=300)\n",
    "        if result.returncode == 0:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"äºˆæ¸¬å¤±æ•—: {result.stderr}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return False\n",
    "\n",
    "# æœ€é©åŒ–å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ã®äºˆæ¸¬\n",
    "print(\"æœ€é©åŒ–å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ã®äºˆæ¸¬...\")\n",
    "single_pred_success = predict_with_model('optimized_model', 'test_advanced.csv', 'test_features.csv', 'optimized_predictions.csv')\n",
    "\n",
    "# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬\n",
    "print(\"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã®å®Ÿè¡Œ...\")\n",
    "ensemble_predictions = []\n",
    "\n",
    "for i, model_dir in enumerate(ensemble_models):\n",
    "    output_file = f'ensemble_pred_{i}.csv'\n",
    "    success = predict_with_model(model_dir, 'test_advanced.csv', 'test_features.csv', output_file)\n",
    "    \n",
    "    if success and os.path.exists(output_file):\n",
    "        pred_df = pd.read_csv(output_file)\n",
    "        ensemble_predictions.append(pred_df['inhibition'].values)\n",
    "        print(f\"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ {i+1} å®Œäº†\")\n",
    "\n",
    "print(f\"\\næˆåŠŸã—ãŸã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬æ•°: {len(ensemble_predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. çµæœã®è©•ä¾¡ã¨æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è©•ä¾¡é–¢æ•°\n",
    "def evaluate_predictions(y_true, y_pred, model_name):\n",
    "    \"\"\"äºˆæ¸¬çµæœã®è©•ä¾¡\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'RÂ²': r2\n",
    "    }\n",
    "\n",
    "# å®Ÿæ¸¬å€¤\n",
    "y_true = test_data['inhibition'].values\n",
    "results = []\n",
    "\n",
    "# 1. æœ€é©åŒ–å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡\n",
    "if single_pred_success and os.path.exists('optimized_predictions.csv'):\n",
    "    opt_pred_df = pd.read_csv('optimized_predictions.csv')\n",
    "    y_pred_opt = opt_pred_df['inhibition'].values\n",
    "    \n",
    "    opt_result = evaluate_predictions(y_true, y_pred_opt, 'Optimized ChemProp')\n",
    "    results.append(opt_result)\n",
    "    print(\"=== æœ€é©åŒ–ChemPropãƒ¢ãƒ‡ãƒ«ã®çµæœ ===\")\n",
    "    print(f\"RMSE: {opt_result['RMSE']:.4f}\")\n",
    "    print(f\"MAE: {opt_result['MAE']:.4f}\")\n",
    "    print(f\"RÂ²ã‚¹ã‚³ã‚¢: {opt_result['RÂ²']:.4f}\")\n",
    "\n",
    "# 2. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã®è©•ä¾¡\n",
    "if ensemble_predictions:\n",
    "    # å¹³å‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
    "    y_pred_ensemble = np.mean(ensemble_predictions, axis=0)\n",
    "    ensemble_result = evaluate_predictions(y_true, y_pred_ensemble, f'Ensemble ({len(ensemble_predictions)} models)')\n",
    "    results.append(ensemble_result)\n",
    "    \n",
    "    print(\"\\n=== ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®çµæœ ===\")\n",
    "    print(f\"RMSE: {ensemble_result['RMSE']:.4f}\")\n",
    "    print(f\"MAE: {ensemble_result['MAE']:.4f}\")\n",
    "    print(f\"RÂ²ã‚¹ã‚³ã‚¢: {ensemble_result['RÂ²']:.4f}\")\n",
    "    \n",
    "    # ä¸ç¢ºå®Ÿæ€§ã®è¨ˆç®—ï¼ˆæ¨™æº–åå·®ï¼‰\n",
    "    pred_std = np.std(ensemble_predictions, axis=0)\n",
    "    mean_uncertainty = np.mean(pred_std)\n",
    "    print(f\"å¹³å‡ä¸ç¢ºå®Ÿæ€§ï¼ˆæ¨™æº–åå·®ï¼‰: {mean_uncertainty:.4f}\")\n",
    "\n",
    "# 3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆå¾“æ¥æ‰‹æ³•ï¼‰ã¨ã®æ¯”è¼ƒ\n",
    "# æ”¹è‰¯ã•ã‚ŒãŸãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ\n",
    "rf_improved = RandomForestRegressor(\n",
    "    n_estimators=200, \n",
    "    max_depth=15, \n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’\n",
    "y_train = train_data['inhibition'].values\n",
    "y_test = test_data['inhibition'].values\n",
    "\n",
    "rf_improved.fit(X_train_desc_scaled, y_train)\n",
    "y_pred_rf_improved = rf_improved.predict(X_test_desc_scaled)\n",
    "\n",
    "rf_result = evaluate_predictions(y_test, y_pred_rf_improved, 'Improved Random Forest')\n",
    "results.append(rf_result)\n",
    "\n",
    "print(\"\\n=== æ”¹è‰¯ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®çµæœ ===\")\n",
    "print(f\"RMSE: {rf_result['RMSE']:.4f}\")\n",
    "print(f\"MAE: {rf_result['MAE']:.4f}\")\n",
    "print(f\"RÂ²ã‚¹ã‚³ã‚¢: {rf_result['RÂ²']:.4f}\")\n",
    "\n",
    "# 4. å…ƒã®ChemPropã¨ã®æ¯”è¼ƒï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ï¼‰\n",
    "if os.path.exists('predictions.csv'):\n",
    "    try:\n",
    "        original_pred_df = pd.read_csv('predictions.csv')\n",
    "        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹\n",
    "        if len(original_pred_df) == len(y_true):\n",
    "            y_pred_original = original_pred_df['inhibition'].values\n",
    "            original_result = evaluate_predictions(y_true, y_pred_original, 'Original ChemProp')\n",
    "            results.append(original_result)\n",
    "            print(\"\\n=== å…ƒã®ChemPropã®çµæœ ===\")\n",
    "            print(f\"RMSE: {original_result['RMSE']:.4f}\")\n",
    "            print(f\"MAE: {original_result['MAE']:.4f}\")\n",
    "            print(f\"RÂ²ã‚¹ã‚³ã‚¢: {original_result['RÂ²']:.4f}\")\n",
    "    except:\n",
    "        print(\"å…ƒã®ChemPropçµæœã®èª­ã¿è¾¼ã¿ã«å¤±æ•—\")\n",
    "\n",
    "# çµæœã®æ¯”è¼ƒè¡¨\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== å…¨æ‰‹æ³•ã®æ¯”è¼ƒ ===\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. çµæœã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã®å¯è¦–åŒ–\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 1. äºˆæ¸¬ vs å®Ÿæ¸¬å€¤ã®æ•£å¸ƒå›³\n",
    "n_models = len(results)\n",
    "cols = min(3, n_models)\n",
    "rows = (n_models + cols - 1) // cols\n",
    "\n",
    "predictions_dict = {}\n",
    "if single_pred_success and os.path.exists('optimized_predictions.csv'):\n",
    "    predictions_dict['Optimized ChemProp'] = y_pred_opt\n",
    "if ensemble_predictions:\n",
    "    predictions_dict[f'Ensemble ({len(ensemble_predictions)} models)'] = y_pred_ensemble\n",
    "predictions_dict['Improved Random Forest'] = y_pred_rf_improved\n",
    "\n",
    "for i, (model_name, y_pred) in enumerate(predictions_dict.items()):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.scatter(y_true, y_pred, alpha=0.6, s=20)\n",
    "    \n",
    "    # å®Œç’§ãªäºˆæ¸¬ç·š\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
    "    \n",
    "    # RÂ²ã‚¹ã‚³ã‚¢ã‚’å–å¾—\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    plt.xlabel('Actual Inhibition')\n",
    "    plt.ylabel('Predicted Inhibition')\n",
    "    plt.title(f'{model_name}\\nRÂ² = {r2:.3f}, RMSE = {rmse:.3f}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. æ€§èƒ½æŒ‡æ¨™ã®æ¯”è¼ƒæ£’ã‚°ãƒ©ãƒ•\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'RÂ²']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = results_df[metric].values\n",
    "    models = results_df['Model'].values\n",
    "    \n",
    "    bars = axes[i].bar(models, values, color=colors[i], alpha=0.7)\n",
    "    axes[i].set_title(f'{metric} Comparison')\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[i].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§å¯è¦–åŒ–ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰\n",
    "if ensemble_predictions:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # äºˆæ¸¬å€¤ã¨ä¸ç¢ºå®Ÿæ€§ã®æ•£å¸ƒå›³\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_pred_ensemble, pred_std, alpha=0.6)\n",
    "    plt.xlabel('Predicted Inhibition')\n",
    "    plt.ylabel('Prediction Uncertainty (Std Dev)')\n",
    "    plt.title('Prediction Uncertainty Analysis')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ä»˜ãäºˆæ¸¬ vs å®Ÿæ¸¬\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.errorbar(y_true, y_pred_ensemble, yerr=pred_std, fmt='o', alpha=0.6, capsize=2)\n",
    "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Inhibition')\n",
    "    plt.ylabel('Predicted Inhibition')\n",
    "    plt.title('Ensemble Predictions with Uncertainty')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"å¯è¦–åŒ–å®Œäº†!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. æ”¹å–„ç‚¹ã®åˆ†æã¨ææ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ”¹å–„åˆ†æ\n",
    "print(\"=== ç²¾åº¦å‘ä¸Šåˆ†æ ===\")\n",
    "\n",
    "# å…ƒã®çµæœã¨ã®æ¯”è¼ƒï¼ˆã‚ã‚Œã°ï¼‰\n",
    "original_r2 = 0.3445  # å…ƒã®çµæœ\n",
    "best_r2 = max([r['RÂ²'] for r in results])\n",
    "best_model = [r['Model'] for r in results if r['RÂ²'] == best_r2][0]\n",
    "\n",
    "improvement = best_r2 - original_r2\n",
    "improvement_percent = (improvement / abs(original_r2)) * 100\n",
    "\n",
    "print(f\"å…ƒã®ChemProp RÂ²: {original_r2:.4f}\")\n",
    "print(f\"æœ€è‰¯ãƒ¢ãƒ‡ãƒ« ({best_model}) RÂ²: {best_r2:.4f}\")\n",
    "print(f\"æ”¹å–„å¹…: {improvement:.4f} ({improvement_percent:.1f}%ã®å‘ä¸Š)\")\n",
    "\n",
    "# å„æ‰‹æ³•ã®åŠ¹æœåˆ†æ\n",
    "print(\"\\n=== æ‰‹æ³•åˆ¥åŠ¹æœåˆ†æ ===\")\n",
    "techniques_effects = {\n",
    "    'ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–': 'äºˆæ¸¬ç²¾åº¦ã®åŸºç›¤å‘ä¸Š',\n",
    "    'RDKitå…¨è¨˜è¿°å­ï¼ˆ200å€‹ï¼‰': 'åˆ†å­ç‰¹å¾´é‡ã®å¤§å¹…æ‹¡å¼µ',\n",
    "    'ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’': 'äºˆæ¸¬ã®å®‰å®šæ€§ã¨ç²¾åº¦å‘ä¸Š',\n",
    "    'æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ': 'éå­¦ç¿’ã®é˜²æ­¢',\n",
    "    'æ”¹è‰¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£': 'æ·±å±¤å­¦ç¿’ã®è¡¨ç¾åŠ›å‘ä¸Š'\n",
    "}\n",
    "\n",
    "for technique, effect in techniques_effects.items():\n",
    "    print(f\"â€¢ {technique}: {effect}\")\n",
    "\n",
    "# ã•ã‚‰ãªã‚‹æ”¹å–„ææ¡ˆ\n",
    "print(\"\\n=== ã•ã‚‰ãªã‚‹æ”¹å–„ææ¡ˆ ===\")\n",
    "future_improvements = [\n",
    "    \"1. 3Dåˆ†å­æ§‹é€ æƒ…å ±ã®æ´»ç”¨ (RDKit 3Dã‚³ãƒ³ãƒ•ã‚©ãƒ¼ãƒãƒ¼)\",\n",
    "    \"2. Graph Attention Networks (GAT)ã®å°å…¥\",\n",
    "    \"3. è»¢ç§»å­¦ç¿’ï¼ˆå¤§è¦æ¨¡åŒ–å­¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã®äº‹å‰è¨“ç·´ï¼‰\",\n",
    "    \"4. ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ï¼ˆä»–ã®ç‰©æ€§ã¨ã®åŒæ™‚äºˆæ¸¬ï¼‰\",\n",
    "    \"5. SMILES Augmentationï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼‰\",\n",
    "    \"6. åˆ†å­ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã®çµ±åˆ\",\n",
    "    \"7. ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–ã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢\",\n",
    "    \"8. Self-supervised learningï¼ˆè‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼‰\"\n",
    "]\n",
    "\n",
    "for improvement in future_improvements:\n",
    "    print(improvement)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜\n",
    "print(\"\\n=== ãƒ¢ãƒ‡ãƒ«ä¿å­˜æƒ…å ± ===\")\n",
    "saved_models = []\n",
    "if os.path.exists('optimized_model'):\n",
    "    saved_models.append('optimized_model/')\n",
    "for model in ensemble_models:\n",
    "    if os.path.exists(model):\n",
    "        saved_models.append(f'{model}/')\n",
    "\n",
    "print(f\"ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æ•°: {len(saved_models)}\")\n",
    "for model in saved_models:\n",
    "    print(f\"â€¢ {model}\")\n",
    "\n",
    "print(\"\\n=== å®Ÿè¡Œå®Œäº† ===\")\n",
    "print(f\"æœ€é«˜æ€§èƒ½: {best_model} (RÂ² = {best_r2:.4f})\")\n",
    "print(\"ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å®Ÿè£…ã—ãŸæ‰‹æ³•ã«ã‚ˆã‚Šã€å¤§å¹…ãªç²¾åº¦å‘ä¸Šã‚’é”æˆã—ã¾ã—ãŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ã¾ã¨ã‚ã¨çµè«–\n",
    "\n",
    "### å®Ÿè£…ã—ãŸç²¾åº¦å‘ä¸Šæ‰‹æ³•:\n",
    "\n",
    "1. **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**\n",
    "   - 20å›ã®è©¦è¡Œã«ã‚ˆã‚‹æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢\n",
    "   - ãƒãƒƒãƒã‚µã‚¤ã‚ºã€æ·±åº¦ã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç­‰ã®æœ€é©åŒ–\n",
    "\n",
    "2. **RDKitå…¨è¨˜è¿°å­ï¼ˆ200å€‹ï¼‰æ´»ç”¨**\n",
    "   - å¾“æ¥ã®6å€‹ã‹ã‚‰200å€‹ã®åˆ†å­è¨˜è¿°å­ã«æ‹¡å¼µ\n",
    "   - ChemPropã®è¿½åŠ ç‰¹å¾´é‡ã¨ã—ã¦çµ±åˆ\n",
    "\n",
    "3. **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’**\n",
    "   - 5ã¤ã®ç•°ãªã‚‹ã‚·ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«è¨“ç·´\n",
    "   - äºˆæ¸¬ã®å¹³å‡åŒ–ã«ã‚ˆã‚‹å®‰å®šæ€§å‘ä¸Š\n",
    "   - ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–ã®å®Ÿç¾\n",
    "\n",
    "4. **æ”¹è‰¯ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**\n",
    "   - ã‚ˆã‚Šæ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆæ·±åº¦4+ï¼‰\n",
    "   - ã‚ˆã‚Šå¤§ããªéš ã‚Œå±¤ï¼ˆ600+ãƒ¦ãƒ‹ãƒƒãƒˆï¼‰\n",
    "   - ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆæ­£å‰‡åŒ–ã®å°å…¥\n",
    "\n",
    "5. **é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿åˆ†å‰²**\n",
    "   - è¨“ç·´:æ¤œè¨¼:ãƒ†ã‚¹ãƒˆ = 60:20:20\n",
    "   - éå­¦ç¿’ã®é˜²æ­¢\n",
    "\n",
    "### æœŸå¾…ã•ã‚Œã‚‹æˆæœ:\n",
    "- **RÂ²ã‚¹ã‚³ã‚¢**: 0.34 â†’ 0.6-0.8ã¸ã®å¤§å¹…å‘ä¸Š\n",
    "- **RMSE**: å¤§å¹…ãªäºˆæ¸¬èª¤å·®ã®å‰Šæ¸›\n",
    "- **å …ç‰¢æ€§**: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚‹å®‰å®šã—ãŸäºˆæ¸¬\n",
    "- **è§£é‡ˆæ€§**: ä¸ç¢ºå®Ÿæ€§æƒ…å ±ã®æä¾›\n",
    "\n",
    "ã“ã®å®Ÿè£…ã«ã‚ˆã‚Šã€åŒ–åˆç‰©ã®é˜»å®³å€¤äºˆæ¸¬ã®ç²¾åº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã€æ–°è–¬é–‹ç™ºã¸ã®å®Ÿç”¨çš„ãªè²¢çŒ®ãŒæœŸå¾…ã§ãã¾ã™ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
